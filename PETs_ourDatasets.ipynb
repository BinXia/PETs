{
 "metadata": {
  "name": "",
  "signature": "sha256:1a47e4e14e3fc3e3ddf89bb09dacd0db5d6c93474422c06ccfd2d42e7e52d0da"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import method\n",
      "\n",
      "import numpy as np\n",
      "import os\n",
      "import re\n",
      "import string\n",
      "import random\n",
      "import time\n",
      "\n",
      "from sklearn.externals import joblib\n",
      "from sklearn.metrics import roc_curve, auc, matthews_corrcoef, f1_score, confusion_matrix, precision_score, accuracy_score\n",
      "\n",
      "\n",
      "Normalization = False;\n",
      "\n",
      "\n",
      "class proteinSample(object):\n",
      "    \"\"\"docstring for protein\"\"\"\n",
      "    def __init__(self):\n",
      "        super(proteinSample, self).__init__()\n",
      "        self._name = str();\t\t\t\t# name of protein\n",
      "        self._sequence = list();\t\t# sequence of protein\n",
      "        self._interface = list();\t\t# AA is interface or non-interface\n",
      "\n",
      "        self._validPos = list();\t\t# the index of valid positive residues\n",
      "        self._validNeg = list();\t\t# the index of valid negative residues\n",
      "\n",
      "        self._PSSM = list();\t\t\t# PSSM of protein\n",
      "        self._PSA = dict(); \t\t\t# predicted solvent accessibility\n",
      "        self._PSS = dict();\t\t\t\t# Protein Second Structure\n",
      "        self._PRSA = dict();\t\t\t# predicted relative solvent accessibility\n",
      "\n",
      "\n",
      "class SubDataset(object):\n",
      "    \"\"\"docstring for SubDataset\"\"\"\n",
      "    def __init__(self):\n",
      "        super(SubDataset, self).__init__()\n",
      "        self.pos = list();\n",
      "        self.neg = list();\n",
      "\n",
      "\n",
      "class dataset(object):\n",
      "    \"\"\"docstring for dataset\"\"\"\n",
      "    def __init__(self):\n",
      "        super(dataset, self).__init__()\n",
      "\n",
      "        # abbreviations to abbreviation\n",
      "        self._threeAA2oneAA = {'GLY':'G','ALA':'A','VAL':'V','LEU':'L','ILE':'I',\\\n",
      "                               'PHE':'F','TRP':'W','TYR':'Y','ASP':'D','HIS':'H',\\\n",
      "                               'ASN':'N','GLU':'E','LYS':'K','GLN':'Q','MET':'M',\\\n",
      "                               'ARG':'R','SER':'S','THR':'T','CYS':'C','PRO':'P'};\n",
      "        self._ss2num = {'C':0,'E':13,'H':-13};\n",
      "        self._prsa2num = {'I':0,'E':13,'B':-13};\n",
      "\n",
      "        # meta dataset\n",
      "        self._Dtestset72 = list();\n",
      "        self._PDBtestset164 = list();\n",
      "\n",
      "\n",
      "        # dataset for training\n",
      "        self._datasetTest = list();\n",
      "\n",
      "\n",
      "        self._confusionMatrix = {'G':0,'A':0,'V':0,'L':0,'I':0,\\\n",
      "                                 'F':0,'W':0,'Y':0,'D':0,'H':0,\\\n",
      "                                 'N':0,'E':0,'K':0,'Q':0,'M':0,\\\n",
      "                                 'R':0,'S':0,'T':0,'C':0,'P':0}\n",
      "        for key in self._confusionMatrix.keys():\n",
      "            self._confusionMatrix[key] = np.zeros((2,2));\n",
      "        self._wholeSequence = list();\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "###############################################################################################\n",
      "###############################################################################################\n",
      "#\tStep I: Load data from file\n",
      "###############################################################################################\n",
      "###############################################################################################\n",
      "\n",
      "    def loadDataFromFile_Dset(self,filename,dataSet):\n",
      "        # traverse the folder for every protein\n",
      "        for protein in os.listdir(filename):\n",
      "            # skip the hiden file\n",
      "            if protein[0] == '.':\n",
      "                continue;\n",
      "            else:\n",
      "                pass;\n",
      "\n",
      "            # initialize name and sequence\n",
      "            name = protein[:-4];\n",
      "            sequence = list();\n",
      "            validPos = list();\n",
      "            validNeg = list();\n",
      "            interface = list();\n",
      "\n",
      "            proteinFilename = filename + '/' + protein;\t\t# get the content of the protein\n",
      "            with open(proteinFilename) as datum:\t\t# open file(auto off)\n",
      "                data = datum.readlines();\t\t\t\t# read whole file line by line\n",
      "            for ln,datum in enumerate(data):\n",
      "                datum = datum.strip();\n",
      "                if datum[0] == '#':\n",
      "                    continue;\n",
      "                else:\n",
      "                    datum = re.split(' +', datum);\n",
      "                    # operate the unusual AA\n",
      "                    if datum[5] in self._threeAA2oneAA.keys():\n",
      "                        sequence.append(self._threeAA2oneAA[datum[5]]);\n",
      "                    else:\n",
      "                        sequence.append('X');\n",
      "                    if datum[2] == '+':\n",
      "                        interface.append('1');\n",
      "                    else:\n",
      "                        interface.append('0');\n",
      "            # append valid residues\n",
      "            for index in range(len(sequence)):\n",
      "                if index < 4 or index > (len(sequence) - 5):\n",
      "                    continue;\n",
      "                else:\n",
      "                    if interface[index] == '1':\n",
      "                        validPos.append(index);\n",
      "                    else:\n",
      "                        validNeg.append(index);\n",
      "\n",
      "            sample = proteinSample();\n",
      "            sample._name = name;\n",
      "            sample._sequence = sequence;\n",
      "            sample._interface = interface;\n",
      "            sample._validPos = validPos;\n",
      "            sample._validNeg = validNeg;\n",
      "            dataSet.append(sample);\n",
      "            # print name,len(sequence);\n",
      "\n",
      "\n",
      "    def loadDataFromFile_PDBset(self,filename,dataSet):\n",
      "\n",
      "        # traverse the folder for every protein\n",
      "        for protein in os.listdir(filename):\n",
      "            # skip the hiden file\n",
      "            if protein[0] == '.':\n",
      "                continue;\n",
      "            else:\n",
      "                pass;\n",
      "            # initialize name and sequence\n",
      "            name = protein;\n",
      "            sequence = list();\n",
      "            validPos = list();\n",
      "            validNeg = list();\n",
      "            interface = list();\n",
      "\n",
      "            proteinFilename = filename + '/' + protein;\t\t# get the content of the protein\n",
      "            with open(proteinFilename) as datum:\t\t# open file(auto off)\n",
      "                data = datum.readlines();\t\t\t\t# read whole file line by line\n",
      "            for ln,datum in enumerate(data):\n",
      "                datum = datum.strip();\t\t\t\n",
      "                datum = re.split(' +', datum);\n",
      "                # operate the unusual AA\n",
      "                if datum[2] in self._threeAA2oneAA.keys():\n",
      "                    sequence.append(self._threeAA2oneAA[datum[2]]);\n",
      "                else:\n",
      "                    sequence.append('X');\n",
      "                if datum[3] == '1':\n",
      "                    interface.append('1');\n",
      "                else:\n",
      "                    interface.append('0');\n",
      "            # append valid residues\n",
      "            for index in range(len(sequence)):\n",
      "                if index < 4 or index > (len(sequence) - 5):\n",
      "                    continue;\n",
      "                else:\n",
      "                    if interface[index] == '1':\n",
      "                        validPos.append(index);\n",
      "                    else:\n",
      "                        validNeg.append(index);\n",
      "            # append the sample into dataset\n",
      "\n",
      "            sample = proteinSample();\n",
      "            sample._name = name;\n",
      "            sample._sequence = sequence;\n",
      "            sample._interface = interface;\n",
      "            sample._validPos = validPos;\n",
      "            sample._validNeg = validNeg;\n",
      "            dataSet.append(sample);\n",
      "            # print name,len(sequence);\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "###############################################################################################\n",
      "###############################################################################################\n",
      "#\tStep II: Prepare the features\n",
      "###############################################################################################\n",
      "###############################################################################################\n",
      "\n",
      "    def caculateEvolutionaryConservationByPSSM(self,dataSet,filename,windowSize,blastVersion):\n",
      "        PSSM = dict();\n",
      "        # traverse the folder for every protein\n",
      "        for protein in os.listdir(filename):\n",
      "            # skip the hiden file\n",
      "            if protein[0] == '.':\n",
      "                continue;\n",
      "            # initialize name and sequence\n",
      "            proteinName = protein[:4].lower() + '_' + protein[5:];\n",
      "            PSSM[proteinName] = list();\n",
      "\n",
      "            proteinFilename = filename + '/' + protein;\t\t# get the content of the protein\n",
      "            with open(proteinFilename) as datum:\t\t# open file(auto off)\n",
      "                data = datum.readlines();\t\t\t\t# read whole file line by line\n",
      "            for ln,datum in enumerate(data):\n",
      "                datum = datum.strip();\t\t\t\n",
      "                if ln >= 3:\n",
      "                    if datum == '':\t\t# the end of the PSSM\n",
      "                        break;\n",
      "                    else:\t\t\t\t# read PSSM\n",
      "                        datum = re.split(' +', datum);\n",
      "                        PSSM[proteinName].append(datum[2:22]);\n",
      "\n",
      "        method.openWindow(dataSet = dataSet, featureName = 'PSSM', relatedN = 20, windowSize = windowSize, featureFromFile = PSSM);\n",
      "\n",
      "\n",
      "    def caculateProteinSecondStructure(self,dataSet,windowSize,dataType):\n",
      "        PSS = dict();\n",
      "        with open('./PSS/%s.out.ss'%dataType) as datum:\n",
      "            data = datum.readlines();\n",
      "\n",
      "        for ln,datum in enumerate(data):\n",
      "            datum = datum.strip();\n",
      "            if datum[0] == '>':\n",
      "                proteinName = datum[1:];\n",
      "                PSS[proteinName] = list();\n",
      "                continue;\n",
      "            else:\n",
      "                # datum = datum.split();\n",
      "                for index in range(len(datum)):\n",
      "                    PSS[proteinName].append(self._ss2num[datum[index]]);\n",
      "\n",
      "        for protein in dataSet:\n",
      "            # init the dict by the window size and average of index\n",
      "            protein._PSS[windowSize] = list();\n",
      "            for index_sequence in xrange(len(protein._sequence)):\n",
      "                protein._PSS[windowSize].append([]);\n",
      "                protein._PSS[windowSize][index_sequence].append(PSS[protein._name][index_sequence]);\n",
      "                if index_sequence < (windowSize-1)/2 or index_sequence > len(protein._sequence)-(windowSize+1)/2:\n",
      "                    for count in range(windowSize-1):\n",
      "                        protein._PSS[windowSize][index_sequence].append('0');\n",
      "                else:\t\t\t\t\t\n",
      "                    for index_window in xrange(1,(windowSize+1)/2):\n",
      "                        protein._PSS[windowSize][index_sequence].append(PSS[protein._name][index_sequence-index_window]);\n",
      "                        protein._PSS[windowSize][index_sequence].append(PSS[protein._name][index_sequence+index_window]);\n",
      "\n",
      "\n",
      "    def caculatePSABySANN(self,filename,dataSet,windowSize):\n",
      "        PSA = dict();\n",
      "        # traverse the folder for every protein\n",
      "        for protein in os.listdir(filename):\n",
      "            # skip the hiden file\n",
      "            if protein[0] == '.':\n",
      "                continue;\n",
      "            # initialize the PRSA of the protein (for the format of name in the dataSet)\n",
      "            proteinName = protein[:4].lower() + '_' + protein[4:-5];\n",
      "            PSA[proteinName] = list();\n",
      "\n",
      "            proteinFilename = filename + '/' + protein;\t# get the content of the protein\n",
      "            with open(proteinFilename) as datum:\t\t# open file(auto off)\n",
      "                data = datum.readlines();\t\t\t\t# read whole file line by line\n",
      "            for ln,datum in enumerate(data):\n",
      "                datum = datum.strip();\n",
      "                if len(datum) == 0 or datum[0] == '#':\n",
      "                    continue;\n",
      "                else:\n",
      "                    datum = re.split(' +', datum);\t\t\t\t\t\n",
      "                    PSA[proteinName].append(int(self._prsa2num[datum[2]]));\n",
      "\n",
      "        # combine the PRSA with dataSet\n",
      "        for protein in dataSet:\n",
      "            # init the dict by the window size and average of index\n",
      "            protein._PSA[windowSize] = list();\n",
      "            for index_sequence in xrange(len(protein._sequence)):\n",
      "                protein._PSA[windowSize].append([]);\n",
      "                protein._PSA[windowSize][index_sequence].append(PSA[protein._name][index_sequence]);\n",
      "                if index_sequence < (windowSize-1)/2 or index_sequence > len(protein._sequence)-(windowSize+1)/2:\n",
      "                    for count in range(windowSize-1):\n",
      "                        protein._PSA[windowSize][index_sequence].append('0');\n",
      "                else:\t\t\t\t\t\n",
      "                    for index_window in xrange(1,(windowSize+1)/2):\n",
      "                        protein._PSA[windowSize][index_sequence].append(PSA[protein._name][index_sequence-index_window]);\n",
      "                        protein._PSA[windowSize][index_sequence].append(PSA[protein._name][index_sequence+index_window]);\n",
      "\n",
      "\n",
      "    def caculatePRSABySurface(self,dataSet,windowSize,dataType):\n",
      "        PRSA = dict();\n",
      "        with open('./PRSA/%s.out.acc20'%dataType) as datum:\n",
      "            data = datum.readlines();\n",
      "\n",
      "        for ln,datum in enumerate(data):\n",
      "            datum = datum.strip();\n",
      "            if datum[0] == '>':\n",
      "                proteinName = datum[1:];\n",
      "                PRSA[proteinName] = list();\n",
      "                continue;\n",
      "            else:\n",
      "                datum = map(float,datum.split());\n",
      "                for index in range(len(datum)):\n",
      "                    PRSA[proteinName].append((int(datum[index])/5)-10);\n",
      "\n",
      "        for protein in dataSet:\n",
      "            # init the dict by the window size and average of index\n",
      "            protein._PRSA[windowSize] = list();\n",
      "            for index_sequence in xrange(len(protein._sequence)):\n",
      "                protein._PRSA[windowSize].append([]);\n",
      "                protein._PRSA[windowSize][index_sequence].append(PRSA[protein._name][index_sequence]);\n",
      "                if index_sequence < (windowSize-1)/2 or index_sequence > len(protein._sequence)-(windowSize+1)/2:\n",
      "                    for count in range(windowSize-1):\n",
      "                        protein._PRSA[windowSize][index_sequence].append('0');\n",
      "                else:\t\t\t\t\t\n",
      "                    for index_window in xrange(1,(windowSize+1)/2):\n",
      "                        protein._PRSA[windowSize][index_sequence].append(PRSA[protein._name][index_sequence-index_window]);\n",
      "                        protein._PRSA[windowSize][index_sequence].append(PRSA[protein._name][index_sequence+index_window]);\n",
      "\n",
      "\n",
      "\n",
      "###############################################################################################\n",
      "###############################################################################################\n",
      "#\tStep III: Output feature into file\n",
      "###############################################################################################\n",
      "###############################################################################################\n",
      "\n",
      "    def outputFeatures(self,dataSet,dataType,samplingMethod = []):\n",
      "        # initialization\n",
      "        data = dict();\n",
      "        datum = list();\n",
      "\n",
      "\n",
      "        # load data\n",
      "        for index_protein,protein in enumerate(dataSet):\n",
      "            # init\n",
      "            data[protein._name] = list();\n",
      "            for index in xrange(len(protein._sequence)):\n",
      "                # init\n",
      "                datum = list();\n",
      "\n",
      "                ## Feature I: Evolutionary Conservation (180 = 20 * 9)\n",
      "                for index_PSSM in xrange(len(protein._PSSM[index])):\n",
      "                    datum.append(method.sigmoid(protein._PSSM[index][index_PSSM],Normalization));\t\t\t\t\t\t\n",
      "                ## Feature II: Protein Second Structure (9)\n",
      "                for count_PSS in range(9):\n",
      "                    datum.append(method.sigmoid(protein._PSS[9][index][count_PSS],Normalization));\n",
      "                ## Feature III: Predicted Relative Solvent Accessibility (1)\n",
      "                for count_PSA in range(9):\n",
      "                    datum.append(method.sigmoid(protein._PSA[9][index][count_PSA],Normalization));\n",
      "                ## Feature IV: Protein Surface\n",
      "                for index_PRSA in protein._PRSA.keys():\n",
      "                    for count_PRSA in range(int(index_PRSA)):\n",
      "                        datum.append(method.sigmoid(protein._PRSA[index_PRSA][index][count_PRSA],Normalization));\t\t\t\t\n",
      "\n",
      "                datum.append(protein._interface[index]);\n",
      "                data[protein._name].append(datum);\n",
      "\n",
      "        # sampling\n",
      "        if dataType == 'Dset186':\n",
      "            if samplingMethod['method'] == '1:1_inner':\n",
      "                sampleSet = list();\n",
      "                for protein in dataSet:\n",
      "                    num = min(len(protein._validPos),len(protein._validNeg));\n",
      "                    samplingList = random.sample(protein._validPos,num);\n",
      "                    for index in samplingList:\n",
      "                        sampleSet.append(data[protein._name][index]);\n",
      "                    samplingList = random.sample(protein._validNeg,num);\n",
      "                    for index in samplingList:\n",
      "                        sampleSet.append(data[protein._name][index]);\n",
      "                self._datasetTraining = sampleSet;\n",
      "\n",
      "            elif samplingMethod['method'] == '1:1_outer':\n",
      "                pos = list();\n",
      "                neg = list();\n",
      "                for protein in dataSet:\n",
      "                    for index in protein._validPos:\n",
      "                        pos.append(data[protein._name][index]);\n",
      "                    for index in protein._validNeg:\n",
      "                        neg.append(data[protein._name][index]);\n",
      "                self._datasetTraining.extend(pos);\n",
      "                self._datasetTraining.extend(random.sample(neg,int(samplingMethod['ratio']*len(pos))));\n",
      "            else:\n",
      "                self.KMeans_Sampling(dataType = dataType, n_clusters = samplingMethod['n_clusters'], ratio_neg = samplingMethod['ratio_neg'], n_skip = samplingMethod['n_skip']);\n",
      "\n",
      "        else:\n",
      "            for name in data.keys():\n",
      "                for count in xrange(len(data[name])):\n",
      "                    if count < 4 or count > (len(data[name]) - 5):\n",
      "                        continue;\n",
      "                    self._datasetTest.append(data[name][count]);\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "###############################################################################################\n",
      "###############################################################################################\n",
      "#\tStep IV: Train the model and apply to practise\n",
      "###############################################################################################\n",
      "###############################################################################################\n",
      "\n",
      "    def findOptimalParameter(self,modelType,threshold):\n",
      "\n",
      "        Recall = 0.0;\n",
      "        Specificity = 0.0;\n",
      "        Precision = 0.0;\n",
      "        AUC = 0.0;\n",
      "        MCC = 0.0;\n",
      "        F_measure = 0.0;\n",
      "        \n",
      "#         print np.shape(self._datasetTest);\n",
      "        convert2float = np.array(self._datasetTest);\n",
      "        testFeatures = np.array(convert2float[:,:-1],dtype=np.float32);\n",
      "        testLabels = np.array(convert2float[:,-1],dtype=np.int8);\n",
      "        # print np.shape(self._datasetTraining);\n",
      "\n",
      "\n",
      "        # print np.shape(trainingFeatures);\n",
      "        # print np.shape(testFeatures);\n",
      "\n",
      "\n",
      "        clf = joblib.load('./ETsModel/%s/ETs.pkl'%modelType);\n",
      "        predict_proba = clf.predict_proba(testFeatures);\n",
      "        predict = clf.predict(testFeatures);\n",
      "        fpr,tpr,_= roc_curve(testLabels,predict_proba[:,1]);\n",
      "        confusion_mat = confusion_matrix(testLabels,predict);\n",
      "\n",
      "\n",
      "\n",
      "        # threshold = sorted(list(set(list(predict_proba[:,1].T))));\n",
      "        # for x in xrange(len(threshold)):\n",
      "        # \tconfusion_mat = np.zeros((2,2));\n",
      "        # \tprint threshold[x];\n",
      "        # \tfor index in xrange(len(predict_proba)):\n",
      "        # \t\tif predict_proba[index,1] >= threshold[x] and testLabels[index] == 1:\n",
      "        # \t\t\tconfusion_mat[1,1] += 1;\n",
      "        # \t\telif predict_proba[index,1] >= threshold[x] and testLabels[index] == 0:\n",
      "        # \t\t\tconfusion_mat[0,1] += 1;\n",
      "        # \t\telif predict_proba[index,1] < threshold[x] and testLabels[index] == 1:\n",
      "        # \t\t\tconfusion_mat[1,0] += 1;\n",
      "        # \t\telse:\n",
      "        # \t\t\tconfusion_mat[0,0] += 1;\n",
      "        # \tRecall,Specificity,Precision,Accuracy,MCC,F_measure = method.caculateConfusionMat(confusion_mat);\n",
      "\n",
      "        # \tprint Recall,Specificity,MCC;\n",
      "\n",
      "        confusion_mat = np.zeros((2,2));\n",
      "        for index in xrange(len(predict_proba)):\n",
      "            if predict_proba[index,1] >= threshold and testLabels[index] == 1:\n",
      "                confusion_mat[1,1] += 1;\n",
      "            elif predict_proba[index,1] >= threshold and testLabels[index] == 0:\n",
      "                confusion_mat[0,1] += 1;\n",
      "            elif predict_proba[index,1] < threshold and testLabels[index] == 1:\n",
      "                confusion_mat[1,0] += 1;\n",
      "            else:\n",
      "                confusion_mat[0,0] += 1;\n",
      "\n",
      "        # Recall,Specificity,Precision,Accuracy,MCC,F_measure = method.caculateConfusionMat(confusion_mat);\n",
      "\n",
      "\n",
      "\n",
      "        # AUC = auc(fpr,tpr);\n",
      "        # MCC = matthews_corrcoef(testLabels,predict);\n",
      "        # F_measure = f1_score(testLabels,predict);\n",
      "\n",
      "        # print 'AUC = %.3f Recall = %.3f Specificity = %.3f Precision = %.3f Accuracy = %.3f MCC = %.3f F-measure = %.3f'%(AUC,Recall,Specificity,Precision,accuracy,MCC,F_measure);\n",
      "        # return 'AUC = %.3f Recall = %.3f Specificity = %.3f Precision = %.3f Accuracy = %.3f MCC = %.3f F-measure = %.3f'%(AUC,Recall,Specificity,Precision,accuracy,MCC,F_measure);\n",
      "        # print '%.3f %.3f %.3f %.3f %.3f %.3f'%(Recall,Specificity,Precision,Accuracy,MCC,F_measure);\n",
      "        return confusion_mat;\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def test():\n",
      "    \n",
      "    databaseSet = {'NACCESS':('NACCESS',0.484),'ASA_Change':('ASA_Change',0.482),'Maximum_Distance':('Maximum_Distance',0.442),'Van_der_Waals_Distance':('Van_der_Waals_Distance',0.402),'PIADA':('PIADA',0.446)}\n",
      "\n",
      "    database = databaseSet['NACCESS'][0];\n",
      "    threshold = databaseSet['NACCESS'][1];\n",
      "\n",
      "    proteinDataset = dataset();\n",
      "    ###### Step I: Load data from file\n",
      "    print 'Step I: Load data frome file...'\n",
      "    ### Setting up\n",
      "    file_address = method.dataset();\n",
      "    file_address.Dtestset72['NACCESS'] = './dataset/NACCESS/Dtestset72';\n",
      "    \n",
      "    file_address.Dtestset72['ASA_Change'] = './dataset/ASA_Change/Dtestset72/interacting';\n",
      "    file_address.PDBtestset164['ASA_Change'] = './dataset/ASA_Change/PDBtestset164/interacting';\n",
      "    \n",
      "    file_address.Dtestset72['Maximum_Distance'] = './dataset/Maximum_Distance/Dtestset72/interacting';\n",
      "    file_address.PDBtestset164['Maximum_Distance'] = './dataset/Maximum_Distance/PDBtestset164/interacting';\n",
      "\n",
      "    file_address.Dtestset72['Van_der_Waals_Distance'] = './dataset/Van_der_Waals_Distance/Dtestset72/interacting';\n",
      "    file_address.PDBtestset164['Van_der_Waals_Distance'] = './dataset/Van_der_Waals_Distance/PDBtestset164/interacting';\n",
      "\n",
      "    file_address.Dtestset72['PIADA'] = './dataset/PIADA/Dtestset72/interacting';\n",
      "    file_address.PDBtestset164['PIADA'] = './dataset/PIADA/PDBtestset164/interacting';\n",
      "\n",
      "    ### Step\n",
      "    if database == 'NACCESS':\n",
      "        proteinDataset.loadDataFromFile_Dset(file_address.Dtestset72[database],proteinDataset._Dtestset72);\n",
      "    else:\n",
      "        proteinDataset.loadDataFromFile_PDBset(file_address.Dtestset72[database],proteinDataset._Dtestset72);\n",
      "#         proteinDataset.loadDataFromFile_PDBset(file_address.PDBtestset164[database],proteinDataset._PDBtestset164);\n",
      "\n",
      "\n",
      "    ###### Step II: Prepare the features\n",
      "    print 'Step II: Prepare the features...'\n",
      "    ### Setting up\n",
      "    PSSM_address = dict();\n",
      "    PSSM_address['Dtestset72'] = './PSSM/blast+/Dtestset72';\n",
      "    PSSM_address['PDBtestset164'] = './PSSM/blast+/PDBtestset164';\n",
      "\n",
      "    PSA_address = './PSA';\n",
      "\n",
      "    ### Feature I: Evolutionary Conservation (180 = 20 * 9)\n",
      "    proteinDataset.caculateEvolutionaryConservationByPSSM(proteinDataset._Dtestset72,PSSM_address['Dtestset72'],9,'BLAST+');\n",
      "#     proteinDataset.caculateEvolutionaryConservationByPSSM(proteinDataset._PDBtestset164,PSSM_address['PDBtestset164'],9,'BLAST+');\n",
      "\n",
      "    ### Feature II: Protein Second Structure (9)\n",
      "    windowSizeList = [1,9]\n",
      "    for windowSize in windowSizeList:\n",
      "        proteinDataset.caculateProteinSecondStructure(proteinDataset._Dtestset72,windowSize,'Dtestset72');\n",
      "#         proteinDataset.caculateProteinSecondStructure(proteinDataset._PDBtestset164,windowSize,'PDBtestset164');\n",
      "\n",
      "    # \tFeature III: Predicted Solvent Accessibility (1)\n",
      "    windowSizeList = [1,9]\n",
      "    for windowSize in windowSizeList:\n",
      "        proteinDataset.caculatePSABySANN(PSA_address, proteinDataset._Dtestset72, windowSize);\n",
      "#         proteinDataset.caculatePSABySANN(PRSA_address, proteinDataset._PDBtestset164, windowSize);\n",
      "\n",
      "    # \tFeature IV: Predicted Relative Solvent Accessibility ()\n",
      "    windowSizeList = [9];\n",
      "    for windowSize in windowSizeList:\n",
      "        proteinDataset.caculatePRSABySurface(proteinDataset._Dtestset72,windowSize,'Dtestset72');\n",
      "#         proteinDataset.caculatePRSABySurface(proteinDataset._PDBtestset164,windowSize,'PDBtestset164');\n",
      "\n",
      "\n",
      "    ###### Step III: Output feature into file\n",
      "    print 'Step III: Output feature into file...'\n",
      "\n",
      "\n",
      "    proteinDataset.outputFeatures(proteinDataset._Dtestset72,'Dtestset72');\n",
      "#     proteinDataset.outputFeatures(proteinDataset._PDBtestset164,'PDBtestset164');\n",
      "\n",
      "\n",
      "    ###### Step IV: Train the model and apply to practise\n",
      "    print 'Step IV: Train the model and apply to practise...'\n",
      "\n",
      "\n",
      "    confusion_mat = proteinDataset.findOptimalParameter(modelType = database,threshold = threshold);\n",
      "\n",
      "    Recall,Specificity,Precision,Accuracy,MCC,F_measure = method.caculateConfusionMat(confusion_mat);\n",
      "    print 'Sen.  Spec. Prec. ACC   MCC   F_measure';\n",
      "    print '%.3f %.3f %.3f %.3f %.3f %.3f'%(Recall,Specificity,Precision,Accuracy,MCC,F_measure);\n",
      "\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\ttest();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Step I: Load data frome file...\n",
        "Step II: Prepare the features..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step III: Output feature into file..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step IV: Train the model and apply to practise..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Sen.  Spec. Prec. ACC   MCC   F_measure"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.648 0.646 0.193 0.646 0.193 0.297\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}