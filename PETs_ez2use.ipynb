{
 "metadata": {
  "name": "",
  "signature": "sha256:989326d2c5117ca4bbc59e795b2163cd1b2450cd367149ffa3f03739669371ee"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import method\n",
      "from result import createReport\n",
      "import numpy as np\n",
      "import os\n",
      "import re\n",
      "import string\n",
      "import random\n",
      "import time\n",
      "\n",
      "from sklearn.externals import joblib\n",
      "from sklearn.metrics import roc_curve, auc, matthews_corrcoef, f1_score, confusion_matrix, precision_score, accuracy_score\n",
      "\n",
      "\n",
      "Normalization = False;\n",
      "\n",
      "\n",
      "class proteinSample(object):\n",
      "    \"\"\"docstring for protein\"\"\"\n",
      "    def __init__(self):\n",
      "        super(proteinSample, self).__init__()\n",
      "        self._name = str();\t\t\t\t# name of protein\n",
      "        self._sequence = list();\t\t# sequence of protein\n",
      "\n",
      "        self._PSSM = list();\t\t\t# PSSM of protein\n",
      "        self._PSA = dict(); \t\t\t# predicted solvent accessibility\n",
      "        self._PSS = dict();\t\t\t\t# Protein Second Structure\n",
      "        self._PRSA = dict();\t\t\t# predicted relative solvent accessibility\n",
      "\n",
      "\n",
      "class SubDataset(object):\n",
      "    \"\"\"docstring for SubDataset\"\"\"\n",
      "    def __init__(self):\n",
      "        super(SubDataset, self).__init__()\n",
      "        self.pos = list();\n",
      "        self.neg = list();\n",
      "\n",
      "\n",
      "class dataset(object):\n",
      "    \"\"\"docstring for dataset\"\"\"\n",
      "    def __init__(self):\n",
      "        super(dataset, self).__init__()\n",
      "\n",
      "        # abbreviations to abbreviation\n",
      "        self._threeAA2oneAA = {'GLY':'G','ALA':'A','VAL':'V','LEU':'L','ILE':'I',\\\n",
      "                               'PHE':'F','TRP':'W','TYR':'Y','ASP':'D','HIS':'H',\\\n",
      "                               'ASN':'N','GLU':'E','LYS':'K','GLN':'Q','MET':'M',\\\n",
      "                               'ARG':'R','SER':'S','THR':'T','CYS':'C','PRO':'P'};\n",
      "        self._ss2num = {'C':0,'E':13,'H':-13};\n",
      "        self._prsa2num = {'I':0,'E':13,'B':-13};\n",
      "\n",
      "        # meta dataset\n",
      "        self._myDataset = list();\n",
      "\n",
      "        # dataset for training\n",
      "        self._datasetTest = list();\n",
      "\n",
      "        self._definition = str();\n",
      "\n",
      "###############################################################################################\n",
      "###############################################################################################\n",
      "#\tStep I: Load data from file\n",
      "###############################################################################################\n",
      "###############################################################################################\n",
      "\n",
      "    def loadDataFromFile_PDBset(self,filename,dataSet):\n",
      "\n",
      "        # traverse the folder for every protein\n",
      "\n",
      "        proteinFilename = filename + 'myDataset';\t\t# get the content of the protein\n",
      "        with open(proteinFilename) as datum:\t\t# open file(auto off)\n",
      "            data = datum.readlines();\t\t\t\t# read whole file line by line\n",
      "\n",
      "        for ln,datum in enumerate(data):\n",
      "            datum = datum.strip();\n",
      "            if ln%2 == 0:\n",
      "                name = datum[1:5]+'_'+datum[5:];\n",
      "            else:\n",
      "                sequence = [x for x in datum];\n",
      "                # append the sample into dataset\n",
      "                sample = proteinSample();\n",
      "                sample._name = name;\n",
      "                sample._sequence = sequence;\n",
      "                dataSet.append(sample);\n",
      "\n",
      "\n",
      "###############################################################################################\n",
      "###############################################################################################\n",
      "#\tStep II: Prepare the features\n",
      "###############################################################################################\n",
      "###############################################################################################\n",
      "\n",
      "    def caculateEvolutionaryConservationByPSSM(self,dataSet,filename,windowSize,blastVersion):\n",
      "        PSSM = dict();\n",
      "        # traverse the folder for every protein\n",
      "        for protein in os.listdir(filename):\n",
      "            # skip the hiden file\n",
      "            if protein[0] == '.':\n",
      "                continue;\n",
      "            # initialize name and sequence\n",
      "            proteinName = protein[:4].lower() + '_' + protein[5:];\n",
      "            PSSM[proteinName] = list();\n",
      "\n",
      "            proteinFilename = filename + '/' + protein;\t\t# get the content of the protein\n",
      "            with open(proteinFilename) as datum:\t\t# open file(auto off)\n",
      "                data = datum.readlines();\t\t\t\t# read whole file line by line\n",
      "            for ln,datum in enumerate(data):\n",
      "                datum = datum.strip();\t\t\t\n",
      "                if ln >= 3:\n",
      "                    if datum == '':\t\t# the end of the PSSM\n",
      "                        break;\n",
      "                    else:\t\t\t\t# read PSSM\n",
      "                        datum = re.split(' +', datum);\n",
      "                        PSSM[proteinName].append(datum[2:22]);\n",
      "\n",
      "        method.openWindow(dataSet = dataSet, featureName = 'PSSM', relatedN = 20, windowSize = windowSize, featureFromFile = PSSM);\n",
      "\n",
      "\n",
      "    def caculateProteinSecondStructure(self,dataSet,windowSize,dataType):\n",
      "        PSS = dict();\n",
      "        with open('./YourDatasetHere/PSS/{0}.out.ss'.format(dataType)) as datum:\n",
      "            data = datum.readlines();\n",
      "\n",
      "        for ln,datum in enumerate(data):\n",
      "            datum = datum.strip();\n",
      "            if datum[0] == '>':\n",
      "                proteinName = datum[1:];\n",
      "                PSS[proteinName] = list();\n",
      "                continue;\n",
      "            else:\n",
      "                # datum = datum.split();\n",
      "                for index in range(len(datum)):\n",
      "                    PSS[proteinName].append(self._ss2num[datum[index]]);\n",
      "\n",
      "        for protein in dataSet:\n",
      "            # init the dict by the window size and average of index\n",
      "            protein._PSS[windowSize] = list();\n",
      "            for index_sequence in xrange(len(protein._sequence)):\n",
      "                protein._PSS[windowSize].append([]);\n",
      "                protein._PSS[windowSize][index_sequence].append(PSS[protein._name][index_sequence]);\n",
      "                if index_sequence < (windowSize-1)/2 or index_sequence > len(protein._sequence)-(windowSize+1)/2:\n",
      "                    for count in range(windowSize-1):\n",
      "                        protein._PSS[windowSize][index_sequence].append('0');\n",
      "                else:\t\t\t\t\t\n",
      "                    for index_window in xrange(1,(windowSize+1)/2):\n",
      "                        protein._PSS[windowSize][index_sequence].append(PSS[protein._name][index_sequence-index_window]);\n",
      "                        protein._PSS[windowSize][index_sequence].append(PSS[protein._name][index_sequence+index_window]);\n",
      "\n",
      "\n",
      "    def caculatePSABySANN(self,filename,dataSet,windowSize):\n",
      "        PSA = dict();\n",
      "        # traverse the folder for every protein\n",
      "        for protein in os.listdir(filename):\n",
      "            # skip the hiden file\n",
      "            if protein[0] == '.':\n",
      "                continue;\n",
      "            # initialize the PRSA of the protein (for the format of name in the dataSet)\n",
      "            proteinName = protein[:4].lower() + '_' + protein[4:-5];\n",
      "            PSA[proteinName] = list();\n",
      "\n",
      "            proteinFilename = filename + '/' + protein;\t# get the content of the protein\n",
      "            with open(proteinFilename) as datum:\t\t# open file(auto off)\n",
      "                data = datum.readlines();\t\t\t\t# read whole file line by line\n",
      "            for ln,datum in enumerate(data):\n",
      "                datum = datum.strip();\n",
      "                if len(datum) == 0 or datum[0] == '#':\n",
      "                    continue;\n",
      "                else:\n",
      "                    datum = re.split(' +', datum);\t\t\t\t\t\n",
      "                    PSA[proteinName].append(int(self._prsa2num[datum[2]]));\n",
      "\n",
      "        # combine the PRSA with dataSet\n",
      "        for protein in dataSet:\n",
      "            # init the dict by the window size and average of index\n",
      "            protein._PSA[windowSize] = list();\n",
      "            for index_sequence in xrange(len(protein._sequence)):\n",
      "                protein._PSA[windowSize].append([]);\n",
      "                protein._PSA[windowSize][index_sequence].append(PSA[protein._name][index_sequence]);\n",
      "                if index_sequence < (windowSize-1)/2 or index_sequence > len(protein._sequence)-(windowSize+1)/2:\n",
      "                    for count in range(windowSize-1):\n",
      "                        protein._PSA[windowSize][index_sequence].append('0');\n",
      "                else:\t\t\t\t\t\n",
      "                    for index_window in xrange(1,(windowSize+1)/2):\n",
      "                        protein._PSA[windowSize][index_sequence].append(PSA[protein._name][index_sequence-index_window]);\n",
      "                        protein._PSA[windowSize][index_sequence].append(PSA[protein._name][index_sequence+index_window]);\n",
      "\n",
      "\n",
      "    def caculatePRSABySurface(self,dataSet,windowSize,dataType):\n",
      "        PRSA = dict();\n",
      "        with open('./YourDatasetHere/PRSA/{0}.out.acc20'.format(dataType)) as datum:\n",
      "            data = datum.readlines();\n",
      "\n",
      "        for ln,datum in enumerate(data):\n",
      "            datum = datum.strip();\n",
      "            if datum[0] == '>':\n",
      "                proteinName = datum[1:];\n",
      "                PRSA[proteinName] = list();\n",
      "                continue;\n",
      "            else:\n",
      "                datum = map(float,datum.split());\n",
      "                for index in range(len(datum)):\n",
      "                    PRSA[proteinName].append((int(datum[index])/5)-10);\n",
      "\n",
      "        for protein in dataSet:\n",
      "            # init the dict by the window size and average of index\n",
      "            protein._PRSA[windowSize] = list();\n",
      "            for index_sequence in xrange(len(protein._sequence)):\n",
      "                protein._PRSA[windowSize].append([]);\n",
      "                protein._PRSA[windowSize][index_sequence].append(PRSA[protein._name][index_sequence]);\n",
      "                if index_sequence < (windowSize-1)/2 or index_sequence > len(protein._sequence)-(windowSize+1)/2:\n",
      "                    for count in range(windowSize-1):\n",
      "                        protein._PRSA[windowSize][index_sequence].append('0');\n",
      "                else:\t\t\t\t\t\n",
      "                    for index_window in xrange(1,(windowSize+1)/2):\n",
      "                        protein._PRSA[windowSize][index_sequence].append(PRSA[protein._name][index_sequence-index_window]);\n",
      "                        protein._PRSA[windowSize][index_sequence].append(PRSA[protein._name][index_sequence+index_window]);\n",
      "\n",
      "\n",
      "\n",
      "###############################################################################################\n",
      "###############################################################################################\n",
      "#\tStep III: Output feature into file\n",
      "###############################################################################################\n",
      "###############################################################################################\n",
      "\n",
      "    def outputFeatures(self,dataSet,dataType,samplingMethod = []):\n",
      "        # initialization\n",
      "        data = dict();\n",
      "        datum = list();\n",
      "\n",
      "\n",
      "        # load data\n",
      "        for index_protein,protein in enumerate(dataSet):\n",
      "            # init\n",
      "            data[protein._name] = list();\n",
      "            for index in xrange(len(protein._sequence)):\n",
      "                # init\n",
      "                datum = list();\n",
      "\n",
      "                ## Feature I: Evolutionary Conservation (180 = 20 * 9)\n",
      "                for index_PSSM in xrange(len(protein._PSSM[index])):\n",
      "                    datum.append(method.sigmoid(protein._PSSM[index][index_PSSM],Normalization));\t\t\t\t\t\t\n",
      "                ## Feature II: Protein Second Structure (9)\n",
      "                for count_PSS in range(9):\n",
      "                    datum.append(method.sigmoid(protein._PSS[9][index][count_PSS],Normalization));\n",
      "                ## Feature III: Predicted Relative Solvent Accessibility (1)\n",
      "                for count_PSA in range(9):\n",
      "                    datum.append(method.sigmoid(protein._PSA[9][index][count_PSA],Normalization));\n",
      "                ## Feature IV: Protein Surface\n",
      "                for index_PRSA in protein._PRSA.keys():\n",
      "                    for count_PRSA in range(int(index_PRSA)):\n",
      "                        datum.append(method.sigmoid(protein._PRSA[index_PRSA][index][count_PRSA],Normalization));\t\t\t\t\n",
      "                \n",
      "                data[protein._name].append(datum);\n",
      "\n",
      "        # sampling\n",
      "        for name in data.keys():\n",
      "            for count in xrange(len(data[name])):\n",
      "                if count < 4 or count > (len(data[name]) - 5):\n",
      "                    continue;\n",
      "                self._datasetTest.append(data[name][count]);\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "###############################################################################################\n",
      "###############################################################################################\n",
      "#\tStep IV: Train the model and apply to practise\n",
      "###############################################################################################\n",
      "###############################################################################################\n",
      "\n",
      "    def findOptimalParameter(self,modelType,threshold):\n",
      "\n",
      "        Recall = 0.0;\n",
      "        Specificity = 0.0;\n",
      "        Precision = 0.0;\n",
      "        AUC = 0.0;\n",
      "        MCC = 0.0;\n",
      "        F_measure = 0.0;\n",
      "        \n",
      "#         print np.shape(self._datasetTest);\n",
      "        convert2float = np.array(self._datasetTest);\n",
      "        testFeatures = np.array(convert2float[:,:],dtype=np.float32);\n",
      "        # print np.shape(self._datasetTraining);\n",
      "\n",
      "\n",
      "        # print np.shape(trainingFeatures);\n",
      "        # print np.shape(testFeatures);\n",
      "\n",
      "\n",
      "        clf = joblib.load('./ETsModel/%s/ETs.pkl'%modelType);\n",
      "        predict_proba = clf.predict_proba(testFeatures);\n",
      "        predict = clf.predict(testFeatures);\n",
      "        \n",
      "        # output result of each protein\n",
      "        predict_count = 0;\n",
      "        for index,protein in enumerate(self._myDataset):\n",
      "            createReport(self._definition,protein._name,protein._sequence,predict[predict_count:predict_count+len(protein._sequence)-8]);\n",
      "            predict_count += len(protein._sequence)-8;\n",
      "\n",
      "\n",
      "\n",
      "def main():\n",
      "    ########################################## The definition of interface:\n",
      "    ########################################## 'NACCESS', 'ASA_Change', 'Maximum_Distance',\n",
      "    definition = 'ASA_Change'                # 'Van_der_Waals_Distance', 'PIADA' \n",
      "    ########################################## The definition above could be used here.\n",
      "    ########################################## The details should be explained in the paper.\n",
      "    \n",
      "    databaseSet = {'NACCESS':('NACCESS',0.484),\\\n",
      "                   'ASA_Change':('ASA_Change',0.482),\\\n",
      "                   'Maximum_Distance':('Maximum_Distance',0.442),\\\n",
      "                   'Van_der_Waals_Distance':('Van_der_Waals_Distance',0.402),\\\n",
      "                   'PIADA':('PIADA',0.446)};\n",
      "    database = databaseSet[definition][0];\n",
      "    threshold = databaseSet[definition][1];\n",
      "    \n",
      "    proteinDataset = dataset();\n",
      "    proteinDataset._definition = definition;\n",
      "    ###### Step I: Load data from file\n",
      "    print 'Step I: Load data frome file...'\n",
      "    ### Setting up\n",
      "    file_address = './YourDatasetHere/dataset/';\n",
      "    proteinDataset.loadDataFromFile_PDBset(file_address,proteinDataset._myDataset);\n",
      "\n",
      "\n",
      "    ###### Step II: Prepare the features\n",
      "    print 'Step II: Prepare the features...'\n",
      "    ### Setting up\n",
      "    PSSM_address = './YourDatasetHere/PSSM/';\n",
      "    PSA_address = './YourDatasetHere/PSA/';\n",
      "\n",
      "    ### Feature I: Evolutionary Conservation (180 = 20 * 9)\n",
      "    proteinDataset.caculateEvolutionaryConservationByPSSM(proteinDataset._myDataset,PSSM_address,9,'BLAST+');\n",
      "\n",
      "    ### Feature II: Protein Second Structure (9)\n",
      "    windowSizeList = [1,9]\n",
      "    for windowSize in windowSizeList:\n",
      "        proteinDataset.caculateProteinSecondStructure(proteinDataset._myDataset,windowSize,'myDataset');\n",
      "\n",
      "    # \tFeature III: Predicted Solvent Accessibility (9)\n",
      "    windowSizeList = [1,9]\n",
      "    for windowSize in windowSizeList:\n",
      "        proteinDataset.caculatePSABySANN(PSA_address, proteinDataset._myDataset, windowSize);\n",
      "\n",
      "    # \tFeature IV: Predicted Relative Solvent Accessibility (9)\n",
      "    windowSizeList = [9];\n",
      "    for windowSize in windowSizeList:\n",
      "        proteinDataset.caculatePRSABySurface(proteinDataset._myDataset,windowSize,'myDataset');\n",
      "\n",
      "\n",
      "    ###### Step III: Output feature into file\n",
      "    print 'Step III: Output feature into file...'\n",
      "    proteinDataset.outputFeatures(proteinDataset._myDataset,'myDataset');\n",
      "\n",
      "\n",
      "    ###### Step IV: Train the model and apply to practise\n",
      "    print 'Step IV: Train the model and apply to practise...'\n",
      "    proteinDataset.findOptimalParameter(modelType = database,threshold = threshold);\n",
      "    print 'Done! Please check the folder \\'result\\'!';\n",
      "\n",
      "if __name__ == '__main__':\tmain();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Step I: Load data frome file...\n",
        "Step II: Prepare the features...\n",
        "Step III: Output feature into file...\n",
        "Step IV: Train the model and apply to practise..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Done! Please check the folder 'result'!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}