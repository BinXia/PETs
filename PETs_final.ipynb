{
 "metadata": {
  "name": "",
  "signature": "sha256:e724ae42d2ace4889627e5199746a1e948553050b999b7d044a0e783743301d9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import method\n",
      "\n",
      "import numpy as np\n",
      "import os\n",
      "import re\n",
      "import string\n",
      "import random\n",
      "import time\n",
      "\n",
      "# import matplotlib.pyplot as plt\n",
      "from sklearn.cluster import KMeans\n",
      "from sklearn.externals import joblib\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "from sklearn.metrics import roc_curve, auc, matthews_corrcoef, f1_score, confusion_matrix, precision_score, accuracy_score\n",
      "\n",
      "\n",
      "Normalization = False;\n",
      "\n",
      "\n",
      "class proteinSample(object):\n",
      "    \"\"\"docstring for protein\"\"\"\n",
      "    def __init__(self):\n",
      "        super(proteinSample, self).__init__()\n",
      "        self._name = str();             # name of protein\n",
      "        self._sequence = list();        # sequence of protein\n",
      "        self._interface = list();        # AA is interface or non-interface\n",
      "\n",
      "        self._validPos = list();        # the index of valid positive residues\n",
      "        self._validNeg = list();        # the index of valid negative residues\n",
      "\n",
      "        self._PSSM = list();            # PSSM of protein\n",
      "        self._PRSA = dict();            # PRSA: predicted relative solvent accessibility\n",
      "        self._PSS = dict();             # Protein Second Structure\n",
      "        self._PSA = dict();             # predicted solvent accessibility\n",
      "\n",
      "\n",
      "class SubDataset(object):\n",
      "\t\"\"\"docstring for SubDataset\"\"\"\n",
      "\tdef __init__(self):\n",
      "\t\tsuper(SubDataset, self).__init__()\n",
      "\t\tself.pos = list();\n",
      "\t\tself.neg = list();\n",
      "\n",
      "\n",
      "class dataset(object):\n",
      "\t\"\"\"docstring for dataset\"\"\"\n",
      "\tdef __init__(self):\n",
      "\t\tsuper(dataset, self).__init__()\n",
      "\t\t\n",
      "\t\t# abbreviations to abbreviation\n",
      "\t\tself._threeAA2oneAA = {'GLY':'G','ALA':'A','VAL':'V','LEU':'L','ILE':'I',\\\n",
      "\t\t\t\t\t\t\t   'PHE':'F','TRP':'W','TYR':'Y','ASP':'D','HIS':'H',\\\n",
      "\t\t\t\t\t\t\t   'ASN':'N','GLU':'E','LYS':'K','GLN':'Q','MET':'M',\\\n",
      "\t\t\t\t\t\t\t   'ARG':'R','SER':'S','THR':'T','CYS':'C','PRO':'P'};\n",
      "\t\tself._ss2num = {'C':0,'E':13,'H':-13};\n",
      "\t\tself._prsa2num = {'I':0,'E':13,'B':-13};\n",
      "\t\t\n",
      "\t\t# meta dataset\n",
      "\t\tself._Dset186 = list();\n",
      "\t\tself._Dtestset72 = list();\n",
      "\t\tself._PDBtestset164 = list();\n",
      "\n",
      "\t\t# dataset\n",
      "\t\tself._integrityDataset = dict();\n",
      "\t\tself._integrityDataset['Dset186'] = dict();\n",
      "\t\tself._integrityDataset_neg = list();\n",
      "\t\tself._integrityDataset['Dtestset72'] = dict();\n",
      "\t\tself._integrityDataset['PDBtestset164'] = dict();\n",
      "\n",
      "\t\t# split dataset\n",
      "\t\tself._datasetSplit = dict();\n",
      "\t\tself._datasetSplit['Dset186'] = list();\n",
      "\t\tself._datasetSplit['Dtestset72'] = list();\n",
      "\t\tself._datasetSplit['PDBtestset164'] = list();\n",
      "\n",
      "\t\t# dataset for training\n",
      "\t\tself._datasetTraining = list();\n",
      "\t\tself._datasetTest = list();\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "###############################################################################################\n",
      "###############################################################################################\n",
      "#\tStep I: Load data from file\n",
      "###############################################################################################\n",
      "###############################################################################################\n",
      "\n",
      "\tdef loadDataFromFile_Dset(self,filename,dataSet):\n",
      "\t\t# traverse the folder for every protein\n",
      "\t\tfor protein in os.listdir(filename):\n",
      "\t\t\t# skip the hiden file\n",
      "\t\t\tif protein[0] == '.':\n",
      "\t\t\t\tcontinue;\n",
      "\t\t\t# initialize name and sequence\n",
      "\t\t\tname = protein[:-4];\n",
      "\t\t\tsequence = list();\n",
      "\t\t\tvalidPos = list();\n",
      "\t\t\tvalidNeg = list();\n",
      "\t\t\tinterface = list();\n",
      "\n",
      "\t\t\tproteinFilename = filename + '/' + protein;\t\t# get the content of the protein\n",
      "\t\t\twith open(proteinFilename) as datum:\t\t# open file(auto off)\n",
      "\t\t\t\tdata = datum.readlines();\t\t\t\t# read whole file line by line\n",
      "\t\t\tfor ln,datum in enumerate(data):\n",
      "\t\t\t\tdatum = datum.strip();\n",
      "\t\t\t\tif datum[0] == '#':\n",
      "\t\t\t\t\tcontinue;\n",
      "\t\t\t\telse:\n",
      "\t\t\t\t\tdatum = re.split(' +', datum);\n",
      "\t\t\t\t\t# operate the unusual AA\n",
      "\t\t\t\t\tif datum[5] in self._threeAA2oneAA.keys():\n",
      "\t\t\t\t\t\tsequence.append(self._threeAA2oneAA[datum[5]]);\n",
      "\t\t\t\t\telse:\n",
      "\t\t\t\t\t\tsequence.append('X');\n",
      "\t\t\t\t\tif datum[2] == '+':\n",
      "\t\t\t\t\t\tinterface.append('1');\n",
      "\t\t\t\t\telse:\n",
      "\t\t\t\t\t\tinterface.append('0');\n",
      "\t\t\t# append valid residues\n",
      "\t\t\tfor index in range(len(sequence)):\n",
      "\t\t\t\tif index < 4 or index > (len(sequence) - 5):\n",
      "\t\t\t\t\tcontinue;\n",
      "\t\t\t\telse:\n",
      "\t\t\t\t\tif interface[index] == '1':\n",
      "\t\t\t\t\t\tvalidPos.append(index);\n",
      "\t\t\t\t\telse:\n",
      "\t\t\t\t\t\tvalidNeg.append(index);\n",
      "\n",
      "\t\t\tsample = proteinSample();\n",
      "\t\t\tsample._name = name;\n",
      "\t\t\tsample._sequence = sequence;\n",
      "\t\t\tsample._interface = interface;\n",
      "\t\t\tsample._validPos = validPos;\n",
      "\t\t\tsample._validNeg = validNeg;\n",
      "\t\t\tdataSet.append(sample);\n",
      "\t\t\t# print name,len(sequence);\n",
      "\n",
      "\n",
      "\tdef loadDataFromFile_PDBset(self,filename,dataSet):\n",
      "\n",
      "\t\t# traverse the folder for every protein\n",
      "\t\tfor protein in os.listdir(filename):\n",
      "\t\t\t# skip the hiden file\n",
      "\t\t\tif protein[0] == '.':\n",
      "\t\t\t\tcontinue;\n",
      "\t\t\t# initialize name and sequence\n",
      "\t\t\tname = protein;\n",
      "\t\t\tsequence = list();\n",
      "\t\t\tvalidPos = list();\n",
      "\t\t\tvalidNeg = list();\n",
      "\t\t\tinterface = list();\n",
      "\n",
      "\t\t\tproteinFilename = filename + '/' + protein;\t\t# get the content of the protein\n",
      "\t\t\twith open(proteinFilename) as datum:\t\t# open file(auto off)\n",
      "\t\t\t\tdata = datum.readlines();\t\t\t\t# read whole file line by line\n",
      "\t\t\tfor ln,datum in enumerate(data):\n",
      "\t\t\t\tdatum = datum.strip();\t\t\t\n",
      "\t\t\t\tdatum = re.split(' +', datum);\n",
      "\t\t\t\t# operate the unusual AA\n",
      "\t\t\t\tif datum[2] in self._threeAA2oneAA.keys():\n",
      "\t\t\t\t\tsequence.append(self._threeAA2oneAA[datum[2]]);\n",
      "\t\t\t\telse:\n",
      "\t\t\t\t\tsequence.append('X');\n",
      "\t\t\t\tif datum[3] == '1':\n",
      "\t\t\t\t\tinterface.append('1');\n",
      "\t\t\t\telse:\n",
      "\t\t\t\t\tinterface.append('0');\n",
      "\t\t\t# append valid residues\n",
      "\t\t\tfor index in range(len(sequence)):\n",
      "\t\t\t\tif index < 4 or index > (len(sequence) - 5):\n",
      "\t\t\t\t\tcontinue;\n",
      "\t\t\t\telse:\n",
      "\t\t\t\t\tif interface[index] == '1':\n",
      "\t\t\t\t\t\tvalidPos.append(index);\n",
      "\t\t\t\t\telse:\n",
      "\t\t\t\t\t\tvalidNeg.append(index);\n",
      "\t\t\t# append the sample into dataset\n",
      "\n",
      "\t\t\tsample = proteinSample();\n",
      "\t\t\tsample._name = name;\n",
      "\t\t\tsample._sequence = sequence;\n",
      "\t\t\tsample._interface = interface;\n",
      "\t\t\tsample._validPos = validPos;\n",
      "\t\t\tsample._validNeg = validNeg;\n",
      "\t\t\tdataSet.append(sample);\n",
      "\t\t\t# print name,len(sequence);\n",
      "\n",
      "\t\t\n",
      "\n",
      "###############################################################################################\n",
      "###############################################################################################\n",
      "#\tStep II: Prepare the features\n",
      "###############################################################################################\n",
      "###############################################################################################\n",
      "\n",
      "\tdef caculateEvolutionaryConservationByPSSM(self,dataSet,filename,windowSize,blastVersion):\n",
      "\t\tPSSM = dict();\n",
      "\t\t# traverse the folder for every protein\n",
      "\t\tfor protein in os.listdir(filename):\n",
      "\t\t\t# skip the hiden file\n",
      "\t\t\tif protein[0] == '.':\n",
      "\t\t\t\tcontinue;\n",
      "\t\t\t# initialize name and sequence\n",
      "\t\t\tproteinName = protein[:4].lower() + '_' + protein[5:];\n",
      "\t\t\tPSSM[proteinName] = list();\n",
      "\n",
      "\t\t\tproteinFilename = filename + '/' + protein;\t\t# get the content of the protein\n",
      "\t\t\twith open(proteinFilename) as datum:\t\t# open file(auto off)\n",
      "\t\t\t\tdata = datum.readlines();\t\t\t\t# read whole file line by line\n",
      "\t\t\tfor ln,datum in enumerate(data):\n",
      "\t\t\t\tdatum = datum.strip();\t\t\t\n",
      "\t\t\t\tif ln >= 3:\n",
      "\t\t\t\t\tif datum == '':\t\t# the end of the PSSM\n",
      "\t\t\t\t\t\tbreak;\n",
      "\t\t\t\t\telse:\t\t\t\t# read PSSM\n",
      "\t\t\t\t\t\tdatum = re.split(' +', datum);\n",
      "\t\t\t\t\t\tPSSM[proteinName].append(datum[2:22]);\n",
      "\t\t\n",
      "\t\tmethod.openWindow(dataSet = dataSet, featureName = 'PSSM', relatedN = 20, windowSize = windowSize, featureFromFile = PSSM);\n",
      "\n",
      "\n",
      "\tdef caculateProteinSecondStructure(self,dataSet,windowSize,dataType):\n",
      "\t\tPSS = dict();\n",
      "\t\twith open('./PSS/%s.out.ss'%dataType) as datum:\n",
      "\t\t\tdata = datum.readlines();\n",
      "\n",
      "\t\tfor ln,datum in enumerate(data):\n",
      "\t\t\tdatum = datum.strip();\n",
      "\t\t\tif datum[0] == '>':\n",
      "\t\t\t\tproteinName = datum[1:];\n",
      "\t\t\t\tPSS[proteinName] = list();\n",
      "\t\t\t\tcontinue;\n",
      "\t\t\telse:\n",
      "\t\t\t\t# datum = datum.split();\n",
      "\t\t\t\tfor index in range(len(datum)):\n",
      "\t\t\t\t\tPSS[proteinName].append(self._ss2num[datum[index]]);\n",
      "\n",
      "\t\tfor protein in dataSet:\n",
      "\t\t\t# init the dict by the window size and average of index\n",
      "\t\t\tprotein._PSS[windowSize] = list();\n",
      "\t\t\tfor index_sequence in xrange(len(protein._sequence)):\n",
      "\t\t\t\tprotein._PSS[windowSize].append([]);\n",
      "\t\t\t\tprotein._PSS[windowSize][index_sequence].append(PSS[protein._name][index_sequence]);\n",
      "\t\t\t\tif index_sequence < (windowSize-1)/2 or index_sequence > len(protein._sequence)-(windowSize+1)/2:\n",
      "\t\t\t\t\tfor count in range(windowSize-1):\n",
      "\t\t\t\t\t\tprotein._PSS[windowSize][index_sequence].append('0');\n",
      "\t\t\t\telse:\t\t\t\t\t\n",
      "\t\t\t\t\tfor index_window in xrange(1,(windowSize+1)/2):\n",
      "\t\t\t\t\t\tprotein._PSS[windowSize][index_sequence].append(PSS[protein._name][index_sequence-index_window]);\n",
      "\t\t\t\t\t\tprotein._PSS[windowSize][index_sequence].append(PSS[protein._name][index_sequence+index_window]);\n",
      "\n",
      "\n",
      "\tdef caculatePSABySANN(self,filename,dataSet,windowSize):\n",
      "\t\tPSA = dict();\n",
      "\t\t# traverse the folder for every protein\n",
      "\t\tfor protein in os.listdir(filename):\n",
      "\t\t\t# skip the hiden file\n",
      "\t\t\tif protein[0] == '.':\n",
      "\t\t\t\tcontinue;\n",
      "\t\t\t# initialize the PRSA of the protein (for the format of name in the dataSet)\n",
      "\t\t\tproteinName = protein[:4].lower() + '_' + protein[4:-5];\n",
      "\t\t\tPSA[proteinName] = list();\n",
      "\n",
      "\t\t\tproteinFilename = filename + '/' + protein;\t# get the content of the protein\n",
      "\t\t\twith open(proteinFilename) as datum:\t\t# open file(auto off)\n",
      "\t\t\t\tdata = datum.readlines();\t\t\t\t# read whole file line by line\n",
      "\t\t\tfor ln,datum in enumerate(data):\n",
      "\t\t\t\tdatum = datum.strip();\n",
      "\t\t\t\tif len(datum) == 0 or datum[0] == '#':\n",
      "\t\t\t\t\tcontinue;\n",
      "\t\t\t\telse:\n",
      "\t\t\t\t\tdatum = re.split(' +', datum);\t\t\t\t\t\n",
      "\t\t\t\t\tPSA[proteinName].append(int(self._prsa2num[datum[2]]));\n",
      "\t\t\t\t\t\n",
      "\t\t# combine the PRSA with dataSet\n",
      "\t\tfor protein in dataSet:\n",
      "\t\t\t# init the dict by the window size and average of index\n",
      "\t\t\tprotein._PSA[windowSize] = list();\n",
      "\t\t\tfor index_sequence in xrange(len(protein._sequence)):\n",
      "\t\t\t\tprotein._PSA[windowSize].append([]);\n",
      "\t\t\t\tprotein._PSA[windowSize][index_sequence].append(PSA[protein._name][index_sequence]);\n",
      "\t\t\t\tif index_sequence < (windowSize-1)/2 or index_sequence > len(protein._sequence)-(windowSize+1)/2:\n",
      "\t\t\t\t\tfor count in range(windowSize-1):\n",
      "\t\t\t\t\t\tprotein._PSA[windowSize][index_sequence].append('0');\n",
      "\t\t\t\telse:\t\t\t\t\t\n",
      "\t\t\t\t\tfor index_window in xrange(1,(windowSize+1)/2):\n",
      "\t\t\t\t\t\tprotein._PSA[windowSize][index_sequence].append(PSA[protein._name][index_sequence-index_window]);\n",
      "\t\t\t\t\t\tprotein._PSA[windowSize][index_sequence].append(PSA[protein._name][index_sequence+index_window]);\n",
      "\n",
      "\n",
      "\tdef caculatePRSABySurface(self,dataSet,windowSize,dataType):\n",
      "\t\tPRSA = dict();\n",
      "\t\twith open('./PRSA/%s.out.acc20'%dataType) as datum:\n",
      "\t\t\tdata = datum.readlines();\n",
      "\n",
      "\t\tfor ln,datum in enumerate(data):\n",
      "\t\t\tdatum = datum.strip();\n",
      "\t\t\tif datum[0] == '>':\n",
      "\t\t\t\tproteinName = datum[1:];\n",
      "\t\t\t\tPRSA[proteinName] = list();\n",
      "\t\t\t\tcontinue;\n",
      "\t\t\telse:\n",
      "\t\t\t\tdatum = map(float,datum.split());\n",
      "\t\t\t\tfor index in range(len(datum)):\n",
      "\t\t\t\t\tPRSA[proteinName].append((int(datum[index])/5)-10);\n",
      "\n",
      "\t\tfor protein in dataSet:\n",
      "\t\t\t# init the dict by the window size and average of index\n",
      "\t\t\tprotein._PRSA[windowSize] = list();\n",
      "\t\t\tfor index_sequence in xrange(len(protein._sequence)):\n",
      "\t\t\t\tprotein._PRSA[windowSize].append([]);\n",
      "\t\t\t\tprotein._PRSA[windowSize][index_sequence].append(PRSA[protein._name][index_sequence]);\n",
      "\t\t\t\tif index_sequence < (windowSize-1)/2 or index_sequence > len(protein._sequence)-(windowSize+1)/2:\n",
      "\t\t\t\t\tfor count in range(windowSize-1):\n",
      "\t\t\t\t\t\tprotein._PRSA[windowSize][index_sequence].append('0');\n",
      "\t\t\t\telse:\t\t\t\t\t\n",
      "\t\t\t\t\tfor index_window in xrange(1,(windowSize+1)/2):\n",
      "\t\t\t\t\t\tprotein._PRSA[windowSize][index_sequence].append(PRSA[protein._name][index_sequence-index_window]);\n",
      "\t\t\t\t\t\tprotein._PRSA[windowSize][index_sequence].append(PRSA[protein._name][index_sequence+index_window]);\n",
      "\n",
      "\n",
      "\n",
      "###############################################################################################\n",
      "###############################################################################################\n",
      "#\tStep III: Output feature into file\n",
      "###############################################################################################\n",
      "###############################################################################################\n",
      "\n",
      "\tdef outputFeatures(self,dataSet,dataType,samplingMethod = []):\n",
      "\t\t# initialization\n",
      "\t\tdata = dict();\n",
      "\t\tdatum = list();\n",
      "\n",
      "\n",
      "\t\t# load data\n",
      "\t\tfor index_protein,protein in enumerate(dataSet):\n",
      "\t\t\t# init\n",
      "\t\t\tdata[protein._name] = list();\n",
      "\t\t\tfor index in xrange(len(protein._sequence)):\n",
      "\t\t\t\t# init\n",
      "\t\t\t\tdatum = list();\n",
      "\n",
      "\t\t\t\t## Feature I: Evolutionary Conservation (180 = 20 * 9)\n",
      "\t\t\t\tfor index_PSSM in xrange(len(protein._PSSM[index])):\n",
      "\t\t\t\t\tdatum.append(method.sigmoid(protein._PSSM[index][index_PSSM],Normalization));\t\t\t\t\t\t\n",
      "\t\t\t\t## Feature II: Protein Second Structure (9)\n",
      "\t\t\t\tfor count_PSS in range(9):\n",
      "\t\t\t\t\tdatum.append(method.sigmoid(protein._PSS[9][index][count_PSS],Normalization));\n",
      "\t\t\t\t## Feature III: Predicted Solvent Accessibility (1)\n",
      "\t\t\t\tfor count_PSA in range(9):\n",
      "\t\t\t\t\tdatum.append(method.sigmoid(protein._PSA[9][index][count_PSA],Normalization));\n",
      "\t\t\t\t## Feature IV: PRSA\n",
      "\t\t\t\tfor index_PRSA in protein._PRSA.keys():\n",
      "\t\t\t\t\tfor count_PRSA in range(int(index_PRSA)):\n",
      "\t\t\t\t\t\tdatum.append(method.sigmoid(protein._PRSA[index_PRSA][index][count_PRSA],Normalization));\t\t\t\t\n",
      "\n",
      "\t\t\t\tdatum.append(protein._interface[index]);\n",
      "\t\t\t\tdata[protein._name].append(datum);\n",
      "\t\t\t\n",
      "\t\t# sampling\n",
      "\t\tif dataType == 'Dset186':\n",
      "\t\t\tif samplingMethod['method'] == '1:1_inner':\n",
      "\t\t\t\tsampleSet = list();\n",
      "\t\t\t\tfor protein in dataSet:\n",
      "\t\t\t\t\tnum = min(len(protein._validPos),len(protein._validNeg));\n",
      "\t\t\t\t\tsamplingList = random.sample(protein._validPos,num);\n",
      "\t\t\t\t\tfor index in samplingList:\n",
      "\t\t\t\t\t\tsampleSet.append(data[protein._name][index]);\n",
      "\t\t\t\t\tsamplingList = random.sample(protein._validNeg,num);\n",
      "\t\t\t\t\tfor index in samplingList:\n",
      "\t\t\t\t\t\tsampleSet.append(data[protein._name][index]);\n",
      "\t\t\t\tself._datasetTraining = sampleSet;\n",
      "\n",
      "\t\t\telif samplingMethod['method'] == '1:1_outer':\n",
      "\t\t\t\tpos = list();\n",
      "\t\t\t\tneg = list();\n",
      "\t\t\t\tfor protein in dataSet:\n",
      "\t\t\t\t\tfor index in protein._validPos:\n",
      "\t\t\t\t\t\tpos.append(data[protein._name][index]);\n",
      "\t\t\t\t\tfor index in protein._validNeg:\n",
      "\t\t\t\t\t\tneg.append(data[protein._name][index]);\n",
      "\t\t\t\tself._datasetTraining.extend(pos);\n",
      "\t\t\t\tself._datasetTraining.extend(random.sample(neg,int(samplingMethod['ratio']*len(pos))));\n",
      "\t\t\telse:\n",
      "\t\t\t\tself.KMeans_Sampling(dataType = dataType, n_clusters = samplingMethod['n_clusters'], ratio_neg = samplingMethod['ratio_neg'], n_skip = samplingMethod['n_skip']);\n",
      "\n",
      "\t\telse:\n",
      "\t\t\tfor name in data.keys():\n",
      "\t\t\t\tfor count in xrange(len(data[name])):\n",
      "\t\t\t\t\tif count < 4 or count > (len(data[name]) - 5):\n",
      "\t\t\t\t\t\tcontinue;\n",
      "\t\t\t\t\tself._datasetTest.append(data[name][count]);\n",
      "\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "###############################################################################################\n",
      "###############################################################################################\n",
      "#\tStep IV: Train the model and apply to practise\n",
      "###############################################################################################\n",
      "###############################################################################################\n",
      "\n",
      "\tdef findOptimalParameter(self,classifierSet,isBin,modelType):\n",
      "\t\t\n",
      "\t\tRecall = 0.0;\n",
      "\t\tSpecificity = 0.0;\n",
      "\t\tPrecision = 0.0;\n",
      "\t\tAUC = 0.0;\n",
      "\t\tMCC = 0.0;\n",
      "\t\tF_measure = 0.0;\n",
      "\n",
      "\n",
      "\t\tif isBin:\n",
      "\t\t\tconvert2float = np.array(self._datasetTraining);\n",
      "\t\t\ttrainingFeatures = np.array(convert2float[:,:-2],dtype=np.float32);\n",
      "\t\t\ttrainingLabels = np.array(convert2float[:,-2],dtype=np.int8);\n",
      "\t\t\tconvert2float = np.array(self._datasetTest);\n",
      "\t\t\ttestFeatures = np.array(convert2float[:,:-1],dtype=np.float32);\n",
      "\t\t\ttestLabels = np.array(convert2float[:,-1],dtype=np.int8);\n",
      "\t\telse:\n",
      "\t\t\tconvert2float = np.array(self._datasetTraining);\n",
      "\t\t\ttrainingFeatures = np.array(convert2float[:,:-1],dtype=np.float32);\n",
      "\t\t\ttrainingLabels = np.array(convert2float[:,-1],dtype=np.int8);\n",
      "\t\t\tconvert2float = np.array(self._datasetTest);\n",
      "\t\t\ttestFeatures = np.array(convert2float[:,:-1],dtype=np.float32);\n",
      "\t\t\ttestLabels = np.array(convert2float[:,-1],dtype=np.int8);\n",
      "\t\t# print np.shape(self._datasetTraining);\n",
      "\t\t\n",
      "\n",
      "\t\t# print np.shape(trainingFeatures);\n",
      "\t\t# print np.shape(testFeatures);\n",
      "\n",
      "\t\t\n",
      "\t\tif classifierSet['classifierMethod'] == 'RFs':\n",
      "\t\t\tclf = RandomForestClassifier(n_estimators=classifierSet['n_estimators'],max_features=classifierSet['max_features'],min_samples_split=1);\n",
      "\t\telif classifierSet['classifierMethod'] == 'ETs':\n",
      "\t\t\tclf = ExtraTreesClassifier(n_estimators=classifierSet['n_estimators'],max_features=classifierSet['max_features'],min_samples_split=1);\n",
      "\n",
      "\t\t# clf = AdaBoostClassifier(clf_pre,n_estimators=classifierSet['Adaboost_n']);\n",
      "\t\tclf = clf.fit(trainingFeatures,trainingLabels);\n",
      "\t\tpredict_proba = clf.predict_proba(testFeatures);\n",
      "\t\tpredict = clf.predict(testFeatures);\n",
      "\t\tfpr,tpr,_= roc_curve(testLabels,predict_proba[:,1]);\n",
      "\t\tconfusion_mat = confusion_matrix(testLabels,predict);\n",
      "\n",
      "# \t\tjoblib.dump(clf, './ETsModel/%s/ETs.pkl'%modelType);\n",
      "# \t\tthreshold = sorted(list(set(list(predict_proba[:,1].T))));\n",
      "# \t\tfor x in xrange(len(threshold)):\n",
      "# \t\t\tconfusion_mat = np.zeros((2,2));\n",
      "# \t\t\tprint threshold[x];\n",
      "# \t\t\tfor index in xrange(len(predict_proba)):\n",
      "# \t\t\t\tif predict_proba[index,1] >= threshold[x] and testLabels[index] == 1:\n",
      "# \t\t\t\t\tconfusion_mat[1,1] += 1;\n",
      "# \t\t\t\telif predict_proba[index,1] >= threshold[x] and testLabels[index] == 0:\n",
      "# \t\t\t\t\tconfusion_mat[0,1] += 1;\n",
      "# \t\t\t\telif predict_proba[index,1] < threshold[x] and testLabels[index] == 1:\n",
      "# \t\t\t\t\tconfusion_mat[1,0] += 1;\n",
      "# \t\t\t\telse:\n",
      "# \t\t\t\t\tconfusion_mat[0,0] += 1;\n",
      "# \t\t\tRecall,Specificity,Precision,Accuracy,MCC,F_measure = method.caculateConfusionMat(confusion_mat);\n",
      "# \t\t\tprint Recall,Specificity,MCC;\n",
      "\n",
      "\t\tthreshold = 0.484;\n",
      "\t\tconfusion_mat = np.zeros((2,2));\n",
      "\t\tfor index in xrange(len(predict_proba)):\n",
      "\t\t\tif predict_proba[index,1] >= threshold and testLabels[index] == 1:\n",
      "\t\t\t\tconfusion_mat[1,1] += 1;\n",
      "\t\t\telif predict_proba[index,1] >= threshold and testLabels[index] == 0:\n",
      "\t\t\t\tconfusion_mat[0,1] += 1;\n",
      "\t\t\telif predict_proba[index,1] < threshold and testLabels[index] == 1:\n",
      "\t\t\t\tconfusion_mat[1,0] += 1;\n",
      "\t\t\telse:\n",
      "\t\t\t\tconfusion_mat[0,0] += 1;\n",
      "\n",
      "\t\tRecall,Specificity,Precision,Accuracy,MCC,F_measure = method.caculateConfusionMat(confusion_mat);\n",
      "\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t# AUC = auc(fpr,tpr);\n",
      "\t\t# MCC = matthews_corrcoef(testLabels,predict);\n",
      "\t\t# F_measure = f1_score(testLabels,predict);\n",
      "\t\t \n",
      "\t\t# print 'AUC = %.3f Recall = %.3f Specificity = %.3f Precision = %.3f Accuracy = %.3f MCC = %.3f F-measure = %.3f'%(AUC,Recall,Specificity,Precision,accuracy,MCC,F_measure);\n",
      "\t\t# return 'AUC = %.3f Recall = %.3f Specificity = %.3f Precision = %.3f Accuracy = %.3f MCC = %.3f F-measure = %.3f'%(AUC,Recall,Specificity,Precision,accuracy,MCC,F_measure);\n",
      "# \t\tprint '%.3f %.3f %.3f %.3f %.3f %.3f'%(Recall,Specificity,Precision,Accuracy,MCC,F_measure);\n",
      "\t\treturn confusion_mat,MCC,Recall,Specificity;\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "###############################################################################################\n",
      "###############################################################################################\n",
      "#\tStep X: Construct classifier by the feature\n",
      "###############################################################################################\n",
      "###############################################################################################\n",
      "\t\n",
      "\tdef KMeans_Sampling(self,dataType,n_clusters,ratio_neg,n_skip):\n",
      "\t\tfor dataSet in self._datasetSplit[dataType]:\n",
      "\t\t\tfor index in xrange(len(dataSet.pos)):\n",
      "\t\t\t\tself._datasetTraining.append(self._integrityDataset[dataType][dataSet.pos[index][-1]]);\n",
      "\n",
      "\t\t# cluster for every leaf\n",
      "\t\tfor num,dataSet in enumerate(self._datasetSplit[dataType]):\n",
      "\t\t\t# initialization\n",
      "\t\t\tdataSet_info = np.array(dataSet.neg);\n",
      "\t\t\tfeatures = np.array(dataSet_info[:,:-2],dtype = np.float32);\n",
      "\t\t\t# labels = np.array(dataSet_info[:,-2],dtype = np.int8);\n",
      "\t\t\tcoordinates = list(dataSet_info[:,-1]);\n",
      "\n",
      "\t\t\t# features = method.UpdateFeatureVector(features,self._retainFeatures_Sampling);\n",
      "\n",
      "\n",
      "\t\t\tcluster = KMeans(n_clusters = n_clusters);\n",
      "\t\t\tcluster.fit(features);\n",
      "\t\t\tlabels = cluster.labels_;\n",
      "\t\t\tdistances = cluster.transform(features);\n",
      "\t\t\t\n",
      "\t\t\t# construct dataset by cluster_labels\n",
      "\t\t\tlabels_type = list(set(labels));\n",
      "\t\t\tdataset_cluster = dict();\n",
      "\t\t\tfor x in labels_type:\n",
      "\t\t\t\tdataset_cluster[x] = list();\n",
      "\t\t\tfor index,sample in enumerate(dataSet_info):\n",
      "\t\t\t\tdataset_cluster[labels[index]].append([sample,distances[index,labels[index]]]);\n",
      "\n",
      "\t\t\tskip = 0;\n",
      "\t\t\t# select the nearer to the center\n",
      "\t\t\tfor x in labels_type:\n",
      "\t\t\t\tdataset_cluster[x].sort(key=lambda x:x[1],reverse=False);\n",
      "\t\t\t\tfor index in xrange(int(ratio_neg*len(dataset_cluster[x]))):\n",
      "\t\t\t\t\tif skip >= n_skip:\n",
      "\t\t\t\t\t\tskip = 0;\n",
      "\t\t\t\t\t\t# print self._integrityDataset[dataType][dataset_cluster[x][index][0][-1]];\n",
      "\t\t\t\t\t\tself._datasetTraining.append(self._integrityDataset[dataType][dataset_cluster[x][index][0][-1]]);\n",
      "\t\t\t\t\telse:\n",
      "\t\t\t\t\t\tskip += 1;\n",
      "\t\t\t\t\t\tcontinue;\n",
      "\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t# print 'Samples: %d'%len(self._datasetTraining);\n",
      "\n",
      "\n",
      "\tdef classifyAminoAcidByFeature(self,dataSet,decisionTree,dataType):\n",
      "\t\t# init the file\n",
      "\t\tos.system('/bin/rm -rf ./subDataset/%s/*'%dataType);\n",
      "\n",
      "\t\t# prepare the dataset for spliting\n",
      "\t\tfor loop in xrange(2):\n",
      "\t\t\tfor index_protein,protein in enumerate(dataSet):\n",
      "\t\t\t\tfor index_sequence in xrange(len(protein._sequence)):\n",
      "\t\t\t\t\tif decisionTree[loop] == 'PSS':\n",
      "\t\t\t\t\t\tmethod.outputFeatures_perAA(dataType,protein,index_protein,index_sequence,protein._PSS[1][index_sequence],decisionTree,loop);\n",
      "\t\t\t\t\telif decisionTree[loop] == 'PSA':\n",
      "\t\t\t\t\t\tmethod.outputFeatures_perAA(dataType,protein,index_protein,index_sequence,protein._PSA[1][index_sequence],decisionTree,loop);\n",
      "\t\t\t\t\telse:\n",
      "\t\t\t\t\t\traise Exception('Error in baseline feature!');\n",
      "\n",
      "\n",
      "\t\t# prepare the parent dataset\n",
      "\t\tdataSet_features = open('./subDataset/features_%s'%dataType,'w');\n",
      "\n",
      "\t\tfor index_protein,protein in enumerate(dataSet):\n",
      "\t\t\tfor index in xrange(len(protein._sequence)):\n",
      "\t\t\t\t# filter the front and rear\n",
      "\t\t\t\tif index < 4 or index > (len(protein._sequence) - 5):\n",
      "\t\t\t\t\tcontinue;\n",
      "\n",
      "\t\t\t\t## Feature I: Evolutionary Conservation (180 = 20 * 9)\n",
      "\t\t\t\tfor index_PSSM in xrange(len(protein._PSSM[index])):\n",
      "\t\t\t\t\tdataSet_features.write('{0} '.format(method.sigmoid(protein._PSSM[index][index_PSSM],Normalization)));\t\t\t\t\t\t\n",
      "\t\t\t\t## Feature III: Protein Second Structure (1)\n",
      "\t\t\t\tfor count_PSS in range(9):\n",
      "\t\t\t\t\tdataSet_features.write('{0} '.format(method.sigmoid(protein._PSS[9][index][count_PSS],Normalization)));\n",
      "\t\t\t\t## Feature IV: Predicted Relative Solvent Accessibility (1)\n",
      "\t\t\t\tfor count_PSA in range(9):\n",
      "\t\t\t\t\tdataSet_features.write('{0} '.format(method.sigmoid(protein._PSA[9][index][count_PSA],Normalization)));\n",
      "\t\t\t\t## Feature V: Protein Surface\n",
      "\t\t\t\tfor index_PRSA in protein._PRSA.keys():\n",
      "\t\t\t\t\tfor count_PRSA in range(int(index_PRSA)):\n",
      "\t\t\t\t\t\tdataSet_features.write('{0} '.format(method.sigmoid(protein._PRSA[index_PRSA][index][count_PRSA],Normalization)));\t\t\t\t\n",
      "\t\t\t\t## End of the feature\n",
      "\t\t\t\tdataSet_features.write('{0} '.format(protein._interface[index]));\n",
      "\t\t\t\tdataSet_features.write('{0}_{1}'.format(index_protein,index));\n",
      "\t\t\t\tdataSet_features.write('\\n');\n",
      "\n",
      "\t\tdataSet_features.close();\n",
      "\n",
      "\n",
      "\tdef loadFeaturesFromFile(self,dataType):\n",
      "\t\t# Load training's or test's features and labels\n",
      "\t\tfileLocation = './subDataset/%s/'%dataType;\n",
      "\t\tfor featuresFile in os.listdir(fileLocation):\n",
      "\t\t\t# skip the hiden file\n",
      "\t\t\tif featuresFile[0] == '.':\n",
      "\t\t\t\tcontinue;\n",
      "\t\t\t# pass hiden layer\n",
      "\t\t\tfileRecognition = featuresFile.split('_');\n",
      "\t\t\tif len(fileRecognition) != 3:\n",
      "\t\t\t\tcontinue;\n",
      "\t\t\t# load the features and labels\n",
      "\t\t\tpreDataset = SubDataset();\n",
      "\t\t\twith open(fileLocation+featuresFile) as datum:\n",
      "\t\t\t\tdata = datum.readlines();\n",
      "\t\t\tfor ln,datum in enumerate(data):\n",
      "\t\t\t\tdatum = datum.strip().split();\n",
      "\t\t\t\tif datum[-2] == '1':\n",
      "\t\t\t\t\tpreDataset.pos.append(datum);\n",
      "\t\t\t\telse:\n",
      "\t\t\t\t\tpreDataset.neg.append(datum);\n",
      "\n",
      "\t\t\tself._datasetSplit[dataType].append(preDataset);\n",
      "\n",
      "\t\twith open('./subDataset/features_%s'%dataType) as datum:\n",
      "\t\t\tdata = datum.readlines();\n",
      "\t\tfor ln,datum in enumerate(data):\n",
      "\t\t\tdatum = datum.strip().split();\n",
      "\t\t\tif datum[-2] == '0' and dataType == 'Dset186':\n",
      "\t\t\t\tself._integrityDataset_neg.append(datum);\n",
      "\t\t\tself._integrityDataset[dataType][datum[-1]] = list()\n",
      "\t\t\tself._integrityDataset[dataType][datum[-1]].extend(datum);\n",
      "\n",
      "\t\t\n",
      "\n",
      "\n",
      "\n",
      "def test():\n",
      "\n",
      "    proteinDataset = dataset();\n",
      "\n",
      "\t###### Step I: Load data from file\n",
      "    print 'Step I: Load data frome file...'\n",
      "\t### Setting up\n",
      "    file_address = method.dataset();\n",
      "    file_address.Dset186['NACCESS'] = './dataset/NACCESS/Dset186';\n",
      "    file_address.Dtestset72['NACCESS'] = './dataset/NACCESS/Dtestset72';\n",
      "\n",
      "    file_address.Dset186['ASA_Change'] = './dataset/ASA_Change/Dset186/interacting';\n",
      "    file_address.Dtestset72['ASA_Change'] = './dataset/ASA_Change/Dtestset72/interacting';\n",
      "    file_address.PDBtestset164['ASA_Change'] = './dataset/ASA_Change/PDBtestset164/interacting';\n",
      "\t\n",
      "    file_address.Dset186['Maximum_Distance'] = './dataset/Maximum_Distance/Dset186/interacting';\n",
      "    file_address.Dtestset72['Maximum_Distance'] = './dataset/Maximum_Distance/Dtestset72/interacting';\n",
      "    file_address.PDBtestset164['Maximum_Distance'] = './dataset/Maximum_Distance/PDBtestset164/interacting';\n",
      "\t\t\n",
      "    file_address.Dset186['Van_der_Waals_Distance'] = './dataset/Van_der_Waals_Distance/Dset186/interacting';\n",
      "    file_address.Dtestset72['Van_der_Waals_Distance'] = './dataset/Van_der_Waals_Distance/Dtestset72/interacting';\n",
      "    file_address.PDBtestset164['Van_der_Waals_Distance'] = './dataset/Van_der_Waals_Distance/PDBtestset164/interacting';\n",
      "\n",
      "    file_address.Dset186['PIADA'] = './dataset/PIADA/Dset186/interacting';\n",
      "    file_address.Dtestset72['PIADA'] = './dataset/PIADA/Dtestset72/interacting';\n",
      "    file_address.PDBtestset164['PIADA'] = './dataset/PIADA/PDBtestset164/interacting';\n",
      "\n",
      "\t### Step\n",
      "    proteinDataset.loadDataFromFile_Dset(file_address.Dset186['NACCESS'],proteinDataset._Dset186);\n",
      "    proteinDataset.loadDataFromFile_Dset(file_address.Dtestset72['NACCESS'],proteinDataset._Dtestset72);\n",
      "\n",
      "# \tproteinDataset.loadDataFromFile_PDBset(file_address.Dset186['ASA_Change'],proteinDataset._Dset186);\n",
      "# \tproteinDataset.loadDataFromFile_PDBset(file_address.Dtestset72['ASA_Change'],proteinDataset._Dtestset72);\n",
      "# \tproteinDataset.loadDataFromFile_PDBset(file_address.PDBtestset164['ASA_Change'],proteinDataset._PDBtestset164);\n",
      "\n",
      "\t###### Step II: Prepare the features\n",
      "    print 'Step II: Prepare the features...'\n",
      "\t### Setting up\n",
      "    PSSM_address = dict();\n",
      "    PSSM_address['Dset186'] = './PSSM/blast+/Dset186';\n",
      "    PSSM_address['Dtestset72'] = './PSSM/blast+/Dtestset72';\n",
      "    PSSM_address['PDBtestset164'] = './PSSM/blast+/PDBtestset164';\n",
      "\n",
      "    PSA_address = './PSA';\n",
      "\n",
      "\t### Feature I: Evolutionary Conservation (180 = 20 * 9)\n",
      "    proteinDataset.caculateEvolutionaryConservationByPSSM(proteinDataset._Dset186,PSSM_address['Dset186'],9,'BLAST+');\n",
      "    proteinDataset.caculateEvolutionaryConservationByPSSM(proteinDataset._Dtestset72,PSSM_address['Dtestset72'],9,'BLAST+');\n",
      "# \tproteinDataset.caculateEvolutionaryConservationByPSSM(proteinDataset._PDBtestset164,PSSM_address['PDBtestset164'],9,'BLAST+');\n",
      "\n",
      "\t### Feature II: Protein Second Structure (9)\n",
      "    windowSizeList = [1,9]\n",
      "    for windowSize in windowSizeList:\n",
      "        proteinDataset.caculateProteinSecondStructure(proteinDataset._Dset186,windowSize,'Dset186');\n",
      "        proteinDataset.caculateProteinSecondStructure(proteinDataset._Dtestset72,windowSize,'Dtestset72');\n",
      "# \t\tproteinDataset.caculateProteinSecondStructure(proteinDataset._PDBtestset164,windowSize,'PDBtestset164');\n",
      "\n",
      "\t# \tFeature III: Predicted Solvent Accessibility (1)\n",
      "    windowSizeList = [1,9]\n",
      "    for windowSize in windowSizeList:\n",
      "        proteinDataset.caculatePSABySANN(PSA_address, proteinDataset._Dset186, windowSize);\n",
      "        proteinDataset.caculatePSABySANN(PSA_address, proteinDataset._Dtestset72, windowSize);\n",
      "# \t\tproteinDataset.caculatePSABySANN(PSA_address, proteinDataset._PDBtestset164, windowSize);\n",
      "\n",
      "\t# \tFeature IV: Predicted Relative Solvent Accessibility ()\n",
      "    windowSizeList = [9]\n",
      "    for windowSize in windowSizeList:\n",
      "        proteinDataset.caculatePRSABySurface(proteinDataset._Dset186,windowSize,'Dset186');\n",
      "        proteinDataset.caculatePRSABySurface(proteinDataset._Dtestset72,windowSize,'Dtestset72');\n",
      "# \t\tproteinDataset.caculatePRSABySurface(proteinDataset._PDBtestset164,windowSize,'PDBtestset164');\n",
      "\n",
      "\n",
      "\t###### Step III: Output feature into file\n",
      "    print 'Step III: Output feature into file...'\n",
      "    proteinDataset.classifyAminoAcidByFeature(proteinDataset._Dset186,['PSS','PSA'],'Dset186');\n",
      "    proteinDataset.loadFeaturesFromFile('Dset186');\n",
      "\n",
      "\n",
      "    sampling_inner = {'method':'1:1_inner'};\n",
      "    sampling_outer = {'method':'1:1_outer', 'ratio':1.1};\n",
      "    sampling_bin = {'method':'bin', 'n_clusters':10, 'ratio_neg':1, 'n_skip':4, 'isBin': True};\n",
      "\n",
      "    proteinDataset.outputFeatures(proteinDataset._Dset186,'Dset186',sampling_bin);\n",
      "    proteinDataset.outputFeatures(proteinDataset._Dtestset72,'Dtestset72');\n",
      "#     proteinDataset.outputFeatures(proteinDataset._PDBtestset164,'PDBtestset164');\n",
      "\n",
      "\n",
      "    ###### Step IV: Train the model and apply to practise\n",
      "    print 'Step IV: Train the model and apply to practise...'\n",
      "\n",
      "    ETs_set = {'classifierMethod':'ETs','n_estimators':500, 'max_features':'sqrt'};\n",
      "\n",
      "\n",
      "    confusion_mat,MCC,Recall,Specificity = proteinDataset.findOptimalParameter(classifierSet = ETs_set, isBin = True, modelType = 'PIADA');\n",
      "\n",
      "    Recall,Specificity,Precision,Accuracy,MCC,F_measure = method.caculateConfusionMat(confusion_mat);\n",
      "    print 'Sen.  Spec. Prec. ACC   MCC   F_measure';\n",
      "    print '%.3f %.3f %.3f %.3f %.3f %.3f'%(Recall,Specificity,Precision,Accuracy,MCC,F_measure);\n",
      "\n",
      "\n",
      "if __name__ == '__main__':  test();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Step I: Load data frome file...\n",
        "Step II: Prepare the features..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step III: Output feature into file..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step IV: Train the model and apply to practise..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Sen.  Spec. Prec. ACC   MCC   F_measure"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.643 0.647 0.192 0.647 0.190 0.296\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}